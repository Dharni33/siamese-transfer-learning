{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda, Input, Subtract, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib; matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'/gpu:0']\n"
     ]
    }
   ],
   "source": [
    "from keras.backend.tensorflow_backend import set_session\n",
    "from utils import limited_gpu_memory_session, get_available_gpus\n",
    "set_session(limited_gpu_memory_session(0.95))\n",
    "print(get_available_gpus())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '/home/Drive2/rishabh/'\n",
    "INIT_WEIGHTS = os.path.join(DATA_DIR, 'init_weights_omniglot.hdf5')\n",
    "CHECKPOINTED_WEIGHTS = os.path.join(DATA_DIR, 'checkpointed_weights_omniglot.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Load the test and train datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19280 images belonging to 964 classes.\n",
      "Found 13180 images belonging to 659 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "image_width = 105\n",
    "image_height = 105\n",
    "image_size = (image_width, image_height)\n",
    "\n",
    "datagen = ImageDataGenerator()\n",
    "\n",
    "train_dir = os.path.join(DATA_DIR, 'omniglot_keras/images_background') # python/\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "        train_dir,  target_size=image_size,\n",
    "        batch_size = 19280,\n",
    "        class_mode='sparse', color_mode=\"grayscale\",\n",
    "        shuffle=True)\n",
    "\n",
    "test_dir = os.path.join(DATA_DIR, 'omniglot_keras/images_evaluation')\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "        test_dir,  target_size=image_size, # this is the target directory\n",
    "        batch_size = 13180, color_mode=\"grayscale\",\n",
    "        class_mode='sparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = train_generator.next()\n",
    "X_val, y_val = test_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import get_alphabet_to_index\n",
    "val_alphabet_to_index = get_alphabet_to_index(test_generator)\n",
    "train_alphabet_to_index = get_alphabet_to_index(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "to_plot = X_train[np.where(y_train == 0)[0]]\n",
    "for i in range(20):\n",
    "    plt.subplot(4, 5, i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(to_plot[i][:,:,0], cmap = 'gray', interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 96, 96, 64)        6464      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 42, 42, 128)       401536    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 21, 21, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 18, 18, 128)       262272    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 6, 6, 256)         524544    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "embedding (Dense)            (None, 4096)              37752832  \n",
      "=================================================================\n",
      "Total params: 38,947,648\n",
      "Trainable params: 38,947,648\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.regularizers import l2\n",
    "from keras.initializers import RandomNormal\n",
    "\n",
    "W_init = RandomNormal(mean=0, stddev=1e-2) #'glorot_uniform'\n",
    "b_init = RandomNormal(mean= 0.5, stddev=1e-2)\n",
    "W_dense_init = RandomNormal(mean=0, stddev = 2e-1)\n",
    "\n",
    "input_shape = (105, 105, 1)\n",
    "reg, reg1 = 1e-3, 2e-3\n",
    "#build convnet to use in each siamese 'leg'\n",
    "convnet = Sequential(name=\"convnet\")\n",
    "convnet.add(Conv2D(64, (10,10), activation='relu',input_shape=input_shape,\n",
    "                   kernel_initializer=W_init, bias_initializer=b_init, kernel_regularizer=l2(reg)))\n",
    "convnet.add(MaxPooling2D())\n",
    "convnet.add(Conv2D(128, (7,7), activation='relu', kernel_regularizer=l2(reg),\n",
    "                   kernel_initializer=W_init))\n",
    "convnet.add(MaxPooling2D())\n",
    "convnet.add(Conv2D(128,(4,4),activation='relu',kernel_initializer=W_init, bias_initializer=b_init, \n",
    "                   kernel_regularizer=l2(reg)))\n",
    "convnet.add(MaxPooling2D())\n",
    "convnet.add(Conv2D(256,(4,4),activation='relu',kernel_initializer=W_init, bias_initializer=b_init, \n",
    "                   kernel_regularizer=l2(reg)))\n",
    "convnet.add(Flatten())\n",
    "convnet.add(Dropout(0.5))\n",
    "convnet.add(Dense(4096,activation=\"sigmoid\", kernel_regularizer=l2(reg1),kernel_initializer=W_dense_init, \n",
    "                  bias_initializer=b_init, name = \"embedding\"))\n",
    "print(convnet.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the loss functions for the siamese and triplet network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def l2_norm(x):\n",
    "    return K.sqrt(K.sum(K.square(x)))\n",
    "\n",
    "MARGIN = 0.2\n",
    "def triplet_loss(y_true, y_pred): # \n",
    "    return K.mean(K.maximum(0.0, y_pred + MARGIN) - y_true * 0, axis = -1)\n",
    "\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    margin = 1\n",
    "    return K.mean((1 - y_true) * K.square(y_pred) +\n",
    "                  y_true * K.square(K.maximum(margin - y_pred, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the siamese network built using the conv net defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 105, 105, 1)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_2 (InputLayer)             (None, 105, 105, 1)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convnet (Sequential)             (None, 4096)          38947648    input_1[0][0]                    \n",
      "                                                                   input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "diff (Subtract)                  (None, 4096)          0           convnet[1][0]                    \n",
      "                                                                   convnet[2][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "abs (Lambda)                     (None, 4096)          0           diff[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "output (Dense)                   (None, 1)             4097        abs[0][0]                        \n",
      "====================================================================================================\n",
      "Total params: 38,951,745\n",
      "Trainable params: 38,951,745\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "left_input = Input(input_shape, name=\"input_1\")\n",
    "encoded_l = convnet(left_input)\n",
    "# with tf.device('/gpu:1'):\n",
    "right_input = Input(input_shape, name=\"input_2\")\n",
    "encoded_r  = convnet(right_input)\n",
    "\n",
    "# merge two encoded inputs with a distance metric\n",
    "diff = Subtract(name=\"diff\")([encoded_l,encoded_r])\n",
    "both = Lambda(lambda x : K.abs(x), output_shape = lambda x: x, name=\"abs\")(diff)\n",
    "prediction = Dense(1, activation='sigmoid', bias_initializer = b_init, name=\"output\")(both)\n",
    "\n",
    "siamese_net = Model(inputs=[left_input, right_input],outputs=prediction, name=\"siamese_net\")\n",
    "siamese_net.summary()\n",
    "os.system(\"rm {}\".format(INIT_WEIGHTS))\n",
    "siamese_net.save_weights(INIT_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.8,\n",
    "              patience=1, verbose = 1, min_lr=1e-8)\n",
    "early_stopping = EarlyStopping(monitor='val_acc',\n",
    "                              min_delta=1e-4,\n",
    "                              patience=25,\n",
    "                              verbose=0, mode='auto')\n",
    "checkpointer = ModelCheckpoint(filepath=CHECKPOINTED_WEIGHTS, verbose=1, save_best_only=True, monitor='oneshot_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "\n",
    "class LossHistory(Callback):\n",
    "    \n",
    "    def __init__(self, X_val, y_val, alphabets={}):\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        self.alphabets = alphabets\n",
    "        self.matches = {}\n",
    "        for x in np.unique(y_val):\n",
    "            self.matches[x] = np.where(y_val == x)[0]\n",
    "        self.true_indices = np.arange(20)\n",
    "        self.one_shot_indices = list(self.one_shot_task(alph) for alph in self.alphabets)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        one_shot_acc = self.one_shot_acc()\n",
    "        logs['oneshot_acc'] = one_shot_acc\n",
    "        print(\" oneshot_acc - {}\".format(one_shot_acc))\n",
    "        \n",
    "    def one_shot_acc(self):\n",
    "        acc = [self.compute_acc(index[0], index[1]) for index in self.one_shot_indices]\n",
    "        return np.mean(acc)\n",
    "    \n",
    "    def compute_acc(self, support, test):\n",
    "        X_support, X_test = self.X_val[support], self.X_val[test]\n",
    "        class_indices = self.compute_pred_class(X_test, X_support)\n",
    "        return (np.sum(class_indices == self.true_indices))/20.0\n",
    "\n",
    "    def one_shot_task(self, alph):\n",
    "        class_arr = self.alphabets[alph]\n",
    "        sample_classes = np.random.choice(class_arr, 20, replace = False)\n",
    "        train_arr, test_arr = [], []\n",
    "        drawers = np.random.choice(20, 2, replace = False)\n",
    "        support_arr = [self.matches[x][drawers[0]] for x in sample_classes] \n",
    "        test_arr = [self.matches[x][drawers[1]] for x in sample_classes]\n",
    "        return (support_arr, test_arr)\n",
    "        \n",
    "    def kernel(self, x, y):\n",
    "        return self.model.predict([x, y]).ravel()\n",
    "\n",
    "    def compute_pred_class(self, X, Y):\n",
    "        n = Y.shape[0]\n",
    "        columns = (np.array([x] * n) for x in X)    \n",
    "        pred_classes = np.array([np.argmax(self.kernel(col, Y)) for col in columns])\n",
    "        return pred_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_alphs = val_alphabet_to_index.keys()\n",
    "val_partial = val_alphs[:len(val_alphs)//2]\n",
    "val_one_shot = set([x for alp in val_partial for x in val_alphabet_to_index[alp]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_oneshot = [i for i in range(len(y_val)) if y_val[i] in val_one_shot]\n",
    "val_train = [i for i in range(len(y_val)) if y_val[i] not in val_one_shot]\n",
    "\n",
    "val_oneshot_index = {k : val_alphabet_to_index[k] for k in val_partial}\n",
    "val_train_index = {k : v for k, v in val_alphabet_to_index.iteritems() if k not in val_partial}\n",
    "loss_history = LossHistory(X_val[val_oneshot], y_val[val_oneshot], val_oneshot_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the data generator to load batches of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Training Pairs..\n",
      "Generating Validation Pairs..\n"
     ]
    }
   ],
   "source": [
    "import utils; reload(utils)\n",
    "from utils import DataGenerator\n",
    "\n",
    "NUM_TRAIN_PAIRS = 150000\n",
    "NUM_VAL_PAIRS = 10000\n",
    "BATCH_SIZE = 128\n",
    "datagen = DataGenerator(X_train, y_train, num_train_pairs = NUM_TRAIN_PAIRS,\n",
    "                        num_val_pairs = NUM_VAL_PAIRS, X_val = X_val[val_train],\n",
    "                        train_alphabet_to_index = train_alphabet_to_index,\n",
    "                        val_alphabet_to_index = val_train_index,\n",
    "                        y_val = y_val[val_train], batch_sz = BATCH_SIZE, verbose = True)\n",
    "datagen.create_data_transformer(rotation_range=10, width_shift_range=0.01, \n",
    "                              height_shift_range=0.01, shear_range=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEPS_PER_EPOCH = NUM_TRAIN_PAIRS // BATCH_SIZE\n",
    "VALIDATION_STEPS = NUM_VAL_PAIRS // BATCH_SIZE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam, SGD\n",
    "learning_rate = 5e-3\n",
    "# adam = Adam(learning_rate)\n",
    "sgd = SGD(lr=learning_rate, decay=5e-3, momentum=0.9, nesterov=True)\n",
    "# scheduler = LearningRateScheduler(lambda epoch : learning_rate * pow(1.02, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "siamese_net.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "siamese_net.load_weights(INIT_WEIGHTS)\n",
    "# siamese_net.load_weights(CHECKPOINTED_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WEIGHTS_PATH = \"/home/rishabh/siamese/keras-oneshot/weights\"\n",
    "# siamese_net.load_weights(WEIGHTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1170/1171 [============================>.] - ETA: 0s - loss: 7.0108 - acc: 0.5005 oneshot_acc - 0.05\n",
      "Epoch 00000: oneshot_acc did not improve\n",
      "1171/1171 [==============================] - 164s - loss: 7.0100 - acc: 0.5005 - val_loss: 6.1181 - val_acc: 0.4998\n",
      "Epoch 2/500\n",
      "1170/1171 [============================>.] - ETA: 0s - loss: 5.4362 - acc: 0.5000 oneshot_acc - 0.05\n",
      "Epoch 00001: oneshot_acc did not improve\n",
      "1171/1171 [==============================] - 165s - loss: 5.4356 - acc: 0.5000 - val_loss: 4.8326 - val_acc: 0.5008\n",
      "Epoch 3/500\n",
      "1170/1171 [============================>.] - ETA: 0s - loss: 4.3589 - acc: 0.4973 oneshot_acc - 0.05\n",
      "Epoch 00002: oneshot_acc did not improve\n",
      "1171/1171 [==============================] - 165s - loss: 4.3585 - acc: 0.4974 - val_loss: 3.9346 - val_acc: 0.5001\n",
      "Epoch 4/500\n",
      "1170/1171 [============================>.] - ETA: 0s - loss: 3.5942 - acc: 0.4991\n",
      "Epoch 00003: reducing learning rate to 0.0255999982357.\n",
      " oneshot_acc - 0.05\n",
      "Epoch 00003: oneshot_acc did not improve\n",
      "1171/1171 [==============================] - 165s - loss: 3.5939 - acc: 0.4991 - val_loss: 3.2862 - val_acc: 0.5004\n",
      "Epoch 5/500\n",
      "1170/1171 [============================>.] - ETA: 0s - loss: 3.0815 - acc: 0.5005\n",
      "Epoch 00004: reducing learning rate to 0.0204799979925.\n",
      " oneshot_acc - 0.05\n",
      "Epoch 00004: oneshot_acc did not improve\n",
      "1171/1171 [==============================] - 165s - loss: 3.0814 - acc: 0.5006 - val_loss: 2.8929 - val_acc: 0.4998\n",
      "Epoch 6/500\n",
      "1170/1171 [============================>.] - ETA: 0s - loss: 2.7627 - acc: 0.4998\n",
      "Epoch 00005: reducing learning rate to 0.016383998096.\n",
      " oneshot_acc - 0.05\n",
      "Epoch 00005: oneshot_acc did not improve\n",
      "1171/1171 [==============================] - 165s - loss: 2.7626 - acc: 0.4998 - val_loss: 2.6407 - val_acc: 0.5004\n",
      "Epoch 7/500\n",
      "1170/1171 [============================>.] - ETA: 0s - loss: 2.5540 - acc: 0.5005\n",
      "Epoch 00006: reducing learning rate to 0.0131071984768.\n",
      " oneshot_acc - 0.05\n",
      "Epoch 00006: oneshot_acc did not improve\n",
      "1171/1171 [==============================] - 165s - loss: 2.5539 - acc: 0.5005 - val_loss: 2.4718 - val_acc: 0.4995\n",
      "Epoch 8/500\n",
      "1170/1171 [============================>.] - ETA: 0s - loss: 2.4122 - acc: 0.4986\n",
      "Epoch 00007: reducing learning rate to 0.0104857586324.\n",
      " oneshot_acc - 0.05\n",
      "Epoch 00007: oneshot_acc did not improve\n",
      "1171/1171 [==============================] - 165s - loss: 2.4121 - acc: 0.4986 - val_loss: 2.3551 - val_acc: 0.4987\n",
      "Epoch 9/500\n",
      "1170/1171 [============================>.] - ETA: 0s - loss: 2.3130 - acc: 0.4994\n",
      "Epoch 00008: reducing learning rate to 0.00838860720396.\n",
      " oneshot_acc - 0.05\n",
      "Epoch 00008: oneshot_acc did not improve\n",
      "1171/1171 [==============================] - 165s - loss: 2.3130 - acc: 0.4994 - val_loss: 2.2725 - val_acc: 0.5008\n",
      "Epoch 10/500\n",
      "1170/1171 [============================>.] - ETA: 0s - loss: 2.2422 - acc: 0.4993\n",
      "Epoch 00009: reducing learning rate to 0.00671088546515.\n",
      " oneshot_acc - 0.05\n",
      "Epoch 00009: oneshot_acc did not improve\n",
      "1171/1171 [==============================] - 165s - loss: 2.2422 - acc: 0.4993 - val_loss: 2.2129 - val_acc: 0.5004\n",
      "Epoch 11/500\n",
      "1170/1171 [============================>.] - ETA: 0s - loss: 2.1908 - acc: 0.4999\n",
      "Epoch 00010: reducing learning rate to 0.00536870844662.\n",
      " oneshot_acc - 0.05\n",
      "Epoch 00010: oneshot_acc did not improve\n",
      "1171/1171 [==============================] - 165s - loss: 2.1908 - acc: 0.4999 - val_loss: 2.1693 - val_acc: 0.4999\n",
      "Epoch 12/500\n",
      "1170/1171 [============================>.] - ETA: 0s - loss: 2.1530 - acc: 0.4977\n",
      "Epoch 00011: reducing learning rate to 0.00429496690631.\n",
      " oneshot_acc - 0.05\n",
      "Epoch 00011: oneshot_acc did not improve\n",
      "1171/1171 [==============================] - 165s - loss: 2.1530 - acc: 0.4977 - val_loss: 2.1371 - val_acc: 0.5001\n",
      "Epoch 13/500\n",
      "1170/1171 [============================>.] - ETA: 0s - loss: 2.1249 - acc: 0.4985\n",
      "Epoch 00012: reducing learning rate to 0.00343597345054.\n",
      " oneshot_acc - 0.05\n",
      "Epoch 00012: oneshot_acc did not improve\n",
      "1171/1171 [==============================] - 165s - loss: 2.1249 - acc: 0.4985 - val_loss: 2.1130 - val_acc: 0.5004\n",
      "Epoch 14/500\n",
      "1170/1171 [============================>.] - ETA: 0s - loss: 2.1039 - acc: 0.4981\n",
      "Epoch 00013: reducing learning rate to 0.00274877883494.\n",
      " oneshot_acc - 0.05\n",
      "Epoch 00013: oneshot_acc did not improve\n",
      "1171/1171 [==============================] - 165s - loss: 2.1039 - acc: 0.4981 - val_loss: 2.0949 - val_acc: 0.4999\n",
      "Epoch 15/500\n",
      "1170/1171 [============================>.] - ETA: 0s - loss: 2.0880 - acc: 0.4993\n",
      "Epoch 00014: reducing learning rate to 0.0021990230307.\n",
      " oneshot_acc - 0.05\n",
      "Epoch 00014: oneshot_acc did not improve\n",
      "1171/1171 [==============================] - 165s - loss: 2.0880 - acc: 0.4992 - val_loss: 2.0812 - val_acc: 0.4998\n",
      "Epoch 16/500\n",
      "1170/1171 [============================>.] - ETA: 0s - loss: 2.0760 - acc: 0.4998\n",
      "Epoch 00015: reducing learning rate to 0.00175921842456.\n",
      " oneshot_acc - 0.05\n",
      "Epoch 00015: oneshot_acc did not improve\n",
      "1171/1171 [==============================] - 165s - loss: 2.0760 - acc: 0.4997 - val_loss: 2.0709 - val_acc: 0.5004\n",
      "Epoch 17/500\n",
      "1170/1171 [============================>.] - ETA: 0s - loss: 2.0669 - acc: 0.4993\n",
      "Epoch 00016: reducing learning rate to 0.00140737472102.\n",
      " oneshot_acc - 0.05\n",
      "Epoch 00016: oneshot_acc did not improve\n",
      "1171/1171 [==============================] - 165s - loss: 2.0669 - acc: 0.4993 - val_loss: 2.0630 - val_acc: 0.4999\n",
      "Epoch 18/500\n",
      "1170/1171 [============================>.] - ETA: 0s - loss: 2.0599 - acc: 0.4983\n",
      "Epoch 00017: reducing learning rate to 0.00112589979544.\n",
      " oneshot_acc - 0.05\n",
      "Epoch 00017: oneshot_acc did not improve\n",
      "1171/1171 [==============================] - 165s - loss: 2.0599 - acc: 0.4982 - val_loss: 2.0569 - val_acc: 0.4998\n",
      "Epoch 19/500\n",
      "1170/1171 [============================>.] - ETA: 0s - loss: 2.0546 - acc: 0.4993\n",
      "Epoch 00018: reducing learning rate to 0.000900719873607.\n",
      " oneshot_acc - 0.05\n",
      "Epoch 00018: oneshot_acc did not improve\n",
      "1171/1171 [==============================] - 165s - loss: 2.0546 - acc: 0.4994 - val_loss: 2.0523 - val_acc: 0.5002\n",
      "Epoch 20/500\n",
      "1170/1171 [============================>.] - ETA: 0s - loss: 2.0505 - acc: 0.4990\n",
      "Epoch 00019: reducing learning rate to 0.000720575917512.\n",
      " oneshot_acc - 0.05\n",
      "Epoch 00019: oneshot_acc did not improve\n",
      "1171/1171 [==============================] - 165s - loss: 2.0505 - acc: 0.4990 - val_loss: 2.0488 - val_acc: 0.5005\n",
      "Epoch 21/500\n",
      "1170/1171 [============================>.] - ETA: 0s - loss: 2.0474 - acc: 0.5003\n",
      "Epoch 00020: reducing learning rate to 0.00057646073401.\n",
      " oneshot_acc - 0.05\n",
      "Epoch 00020: oneshot_acc did not improve\n",
      "1171/1171 [==============================] - 165s - loss: 2.0474 - acc: 0.5002 - val_loss: 2.0460 - val_acc: 0.4995\n",
      "Epoch 22/500\n",
      "1170/1171 [============================>.] - ETA: 0s - loss: 2.0449 - acc: 0.4973\n",
      "Epoch 00021: reducing learning rate to 0.000461168587208.\n",
      " oneshot_acc - 0.05\n",
      "Epoch 00021: oneshot_acc did not improve\n",
      "1171/1171 [==============================] - 165s - loss: 2.0449 - acc: 0.4973 - val_loss: 2.0439 - val_acc: 0.5007\n",
      "Epoch 23/500\n",
      "1170/1171 [============================>.] - ETA: 0s - loss: 2.0430 - acc: 0.4976\n",
      "Epoch 00022: reducing learning rate to 0.000368934869766.\n",
      " oneshot_acc - 0.05\n",
      "Epoch 00022: oneshot_acc did not improve\n",
      "1171/1171 [==============================] - 165s - loss: 2.0430 - acc: 0.4976 - val_loss: 2.0422 - val_acc: 0.5002\n",
      "Epoch 24/500\n",
      "1170/1171 [============================>.] - ETA: 0s - loss: 2.0416 - acc: 0.4998\n",
      "Epoch 00023: reducing learning rate to 0.000295147905126.\n",
      " oneshot_acc - 0.05\n",
      "Epoch 00023: oneshot_acc did not improve\n",
      "1171/1171 [==============================] - 165s - loss: 2.0416 - acc: 0.4998 - val_loss: 2.0410 - val_acc: 0.5006\n",
      "Epoch 25/500\n",
      "1170/1171 [============================>.] - ETA: 0s - loss: 2.0405 - acc: 0.4981\n",
      "Epoch 00024: reducing learning rate to 0.000236118328758.\n",
      " oneshot_acc - 0.05\n",
      "Epoch 00024: oneshot_acc did not improve\n",
      "1171/1171 [==============================] - 165s - loss: 2.0405 - acc: 0.4981 - val_loss: 2.0401 - val_acc: 0.4996\n",
      "Epoch 26/500\n",
      "1170/1171 [============================>.] - ETA: 0s - loss: 2.0397 - acc: 0.4993\n",
      "Epoch 00025: reducing learning rate to 0.000188894663006.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " oneshot_acc - 0.05\n",
      "Epoch 00025: oneshot_acc did not improve\n",
      "1171/1171 [==============================] - 165s - loss: 2.0397 - acc: 0.4993 - val_loss: 2.0394 - val_acc: 0.4996\n",
      "Epoch 27/500\n",
      "1170/1171 [============================>.] - ETA: 0s - loss: 2.0391 - acc: 0.4994\n",
      "Epoch 00026: reducing learning rate to 0.000151115725748.\n",
      " oneshot_acc - 0.05\n",
      "Epoch 00026: oneshot_acc did not improve\n",
      "1171/1171 [==============================] - 165s - loss: 2.0391 - acc: 0.4993 - val_loss: 2.0388 - val_acc: 0.4999\n",
      "Epoch 28/500\n",
      "1170/1171 [============================>.] - ETA: 0s - loss: 2.0386 - acc: 0.4998\n",
      "Epoch 00027: reducing learning rate to 0.000120892585255.\n",
      " oneshot_acc - 0.05\n",
      "Epoch 00027: oneshot_acc did not improve\n",
      "1171/1171 [==============================] - 165s - loss: 2.0386 - acc: 0.4999 - val_loss: 2.0384 - val_acc: 0.4985\n"
     ]
    }
   ],
   "source": [
    "history = siamese_net.fit_generator(\n",
    "        datagen.next_train(),\n",
    "        steps_per_epoch=STEPS_PER_EPOCH,\n",
    "        epochs=500,\n",
    "        validation_data = datagen.next_val(),\n",
    "        validation_steps = VALIDATION_STEPS,\n",
    "        callbacks = [reduce_lr, early_stopping, loss_history, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0QAAAHwCAYAAACG3a9kAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAMC6JRABAADr1v8Biv3jOo6qy8EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7c9caaf050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "% matplotlib inline\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\n",
    "f.set_figheight(8)\n",
    "f.set_figwidth(14)\n",
    "\n",
    "ax1.plot(history.history['loss'])\n",
    "ax1.set_title('model loss')\n",
    "ax1.set_ylabel('loss')\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.legend(['train_loss' 'val'], loc='upper left')\n",
    "\n",
    "ax2.plot(history.history['acc'])\n",
    "# ax2.plot(history.history['val_acc'])\n",
    "ax2.set_title('model acc')\n",
    "ax2.set_ylabel('acc')\n",
    "ax2.set_xlabel('epoch')\n",
    "ax2.legend(['train_acc' 'val'], loc='upper left')\n",
    "\n",
    "f.savefig('siamese_omniglot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "siamese_net.load_weights(CHECKPOINTED_WEIGHTS)\n",
    "for layer in siamese_net.layers:\n",
    "    layer.trainable = False\n",
    "siamese_net.summary()\n",
    "siamese_net.save(os.path.join(DATA_DIR, 'siamese_omniglot1.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "siamese_net = load_model(os.path.join(DATA_DIR, 'siamese_omniglot.h5'))\n",
    "siamese_net.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history = siamese_net.evaluate_generator(datagen.next_val(),\n",
    "        steps=VALIDATION_STEPS)\n",
    "print(\"Loss {} Accuracy {}\".format(history[0], history[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
