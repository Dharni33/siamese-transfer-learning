{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project: ResNet-50 for Cats.Vs.Dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, merge, Input, Lambda, Reshape\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras.preprocessing import image\n",
    "from keras.optimizers import SGD, Nadam\n",
    "from keras.utils.data_utils import get_file\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "import random\n",
    "from collections import Counter\n",
    "import tensorflow as tf\n",
    "from utils import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "config.gpu_options.allow_growth = True \n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "GPUs = get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(GPUs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '/home/Drive2/rishabh/'\n",
    "TRAIN_FEATURES = os.path.join(DATA_DIR, 'bottleneck_features_train_activation_46.npy')\n",
    "TEST_FEATURES = os.path.join(DATA_DIR, 'bottleneck_features_test_activation_46.npy')\n",
    "CHECKPOINTED_WEIGHTS = os.path.join(DATA_DIR, 'checkpointed_weights_siamese.hdf5')\n",
    "INIT_WEIGHTS = os.path.join(DATA_DIR, 'init_weights_base_siamese.hdf5')\n",
    "MODEL_IMAGE = os.path.join(DATA_DIR, 'resnet50.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "- The images in train folder are divided into a training set and a validation set.\n",
    "- The images both in training set and validation set are separately divided into two folders -- cat and dog according to their lables.\n",
    "\n",
    "*(the two steps above were finished in  Preprocessing train dataset.ipynb)*\n",
    "\n",
    "- The RGB color values of the images are rescaled to 0~1.\n",
    "- The size of the images are resized to 224*224.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_width = 224\n",
    "image_height = 224\n",
    "image_size = (image_width, image_height)\n",
    "BATCH_SIZE = 2000\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255)#, \n",
    "#                 zca_whitening=True, zca_epsilon=1e-5)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'mytrain',  # this is the target directory\n",
    "        target_size=image_size,  # all images will be resized to 224x224\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='binary')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'myvalid',  # this is the target directory\n",
    "        target_size=image_size,  # all images will be resized to 224x224\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x, y = train_generator.next()\n",
    "\n",
    "# plt.figure(figsize=(16, 8))\n",
    "# for i, (img, label) in enumerate(zip(x, y)):\n",
    "#     if i >= 18:\n",
    "#         break\n",
    "#     plt.subplot(3, 6, i+1)\n",
    "#     if label == 1:\n",
    "#         plt.title('dog')\n",
    "#     else:\n",
    "#         plt.title('cat')\n",
    "#     plt.axis('off')\n",
    "#     plt.imshow(img, interpolation=\"nearest\")\n",
    "\n",
    "# # Delete the dataset generated above\n",
    "# del x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = train_generator.next()\n",
    "X_test, y_test = test_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the structure of ResNet-50 for Cats.Vs.Dogs\n",
    "\n",
    "1. Build the structure of ResNet-50 without top layer.\n",
    "2. Add top layer to ResNet-50.\n",
    "3. Setup training attribute.\n",
    "4. Compile the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Build the structure of ResNet-50 without top layer. \n",
    "Pass the train and test data throught the network and del the model from memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    margin = 1\n",
    "    return K.mean((1 - y_true) * K.square(y_pred) +\n",
    "                  y_true * K.square(K.maximum(margin - y_pred, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "size = (image_width, image_height, 3)\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "base_model.summary()\n",
    "Image(filename=MODEL_IMAGE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from keras.layers.pooling import AveragePooling2D\n",
    "\n",
    "def create_train_test_features():\n",
    "    with tf.device(GPUs[0]):\n",
    "        x = base_model.get_layer('activation_46').output\n",
    "        x = AveragePooling2D((7, 7), name='avg_pool')(x)\n",
    "        flatten = Flatten()(x)\n",
    "        model = Model(inputs = base_model.input, outputs = flatten)\n",
    "\n",
    "    #   Train data\n",
    "    bottleneck_features_train = model.predict(X_train)\n",
    "    # save the output as a Numpy array\n",
    "    np.save(open(TRAIN_FEATURES, 'w'), bottleneck_features_train)\n",
    "\n",
    "    # Test data\n",
    "    bottleneck_features_test = model.predict(X_test)\n",
    "    # save the output as a Numpy array\n",
    "    np.save(open(TEST_FEATURES, 'w'), bottleneck_features_test)\n",
    "    del model\n",
    "    \n",
    "# if not os.path.exists(TRAIN_FEATURES):\n",
    "    create_train_test_features()\n",
    "del base_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.regularizers import l2\n",
    "\n",
    "INPUT_SHAPE = 2048\n",
    "reg = 1e-4\n",
    "\n",
    "GPU = GPUs[0]\n",
    "with tf.device(GPU):\n",
    "    base_network = Sequential()\n",
    "    base_network.add(Dense(8094, input_shape=(INPUT_SHAPE,), kernel_regularizer = l2(reg)))\n",
    "    base_network.add(BatchNormalization())\n",
    "    base_network.add(Activation('relu'))\n",
    "    base_network.add(Dense(4096, input_shape=(INPUT_SHAPE,), kernel_regularizer = l2(reg)))\n",
    "    base_network.add(BatchNormalization())\n",
    "    base_network.add(Activation('relu'))\n",
    "    base_network.add(Dense(4096, kernel_regularizer = l2(reg)))\n",
    "    base_network.add(BatchNormalization())\n",
    "    base_network.add(Activation('relu'))\n",
    "    base_network.add(Dense(1024, kernel_regularizer = l2(reg), activation='tanh'))\n",
    "    base_network.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Siamese Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(GPUs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "\n",
    "with tf.device(GPU):\n",
    "    input_a = Input(shape=(INPUT_SHAPE,))\n",
    "    processed_a = base_network(input_a)\n",
    "    input_b = Input(shape=(INPUT_SHAPE,))\n",
    "    processed_b = base_network(input_b)\n",
    "    cos_distance = layers.Dot(axes = -1, normalize = True)([processed_a, processed_b])\n",
    "    siamese_net = Model([input_a, input_b], cos_distance)\n",
    "siamese_net.save_weights(INIT_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_net.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Train ResNet-50 for Cats.Vs.Dogs and Save the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Compile the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
    "              patience=5, verbose = 1, min_lr=1e-8)\n",
    "early_stopping = EarlyStopping(monitor='train_loss',\n",
    "                              min_delta=1e-4,\n",
    "                              patience=15,\n",
    "                              verbose=0, mode='auto')\n",
    "checkpointer = ModelCheckpoint(filepath=CHECKPOINTED_WEIGHTS, verbose=1, save_best_only=True, period=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRAIN_PAIRS = 1000\n",
    "NUM_VAL_PAIRS = 20000\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_data = np.load(TRAIN_FEATURES)\n",
    "datagen = DataGenerator(train_data, y_train, batch_sz = BATCH_SIZE, num_train_pairs = NUM_TRAIN_PAIRS, \n",
    "                        num_val_pairs = NUM_VAL_PAIRS, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nadam = Nadam(lr=1e-2)\n",
    "siamese_net.compile(optimizer=nadam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "siamese_net.load_weights(INIT_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "STEPS_PER_EPOCH = NUM_TRAIN_PAIRS//BATCH_SIZE\n",
    "VALIDATION_STEPS = NUM_VAL_PAIRS//BATCH_SIZE\n",
    "\n",
    "# for lr in np.logspace(-5, 0, 20):\n",
    "#     nadam = Nadam(lr=lr)\n",
    "#     siamese_net.compile(optimizer=nadam, loss='binary_crossentropy')\n",
    "#     siamese_net.load_weights(INIT_WEIGHTS)\n",
    "history = siamese_net.fit_generator(\n",
    "        datagen.next_train(),\n",
    "        steps_per_epoch=STEPS_PER_EPOCH,\n",
    "        epochs=250,\n",
    "        validation_data=datagen.next_val(),\n",
    "        validation_steps=VALIDATION_STEPS,\n",
    "        callbacks = [reduce_lr, checkpointer])\n",
    "#     losses = history.history\n",
    "#     print(\"lr:{} loss:{} val_loss:{}\".format(lr, losses['loss'][-1], losses['val_loss'][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import h5py\n",
    "# siamese_net.save_weights('saved_weights_model.h5', overwrite=True)\n",
    "# del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "siamese_net.load_weights('checkpointed_weights.hdf5')\n",
    "test_data = np.load(open('bottleneck_features_test.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "    \n",
    "def kernel(x, y):\n",
    "    return siamese_net.predict([x, y])[:, 0]\n",
    "\n",
    "def compute_kernel(X, Y):\n",
    "    n1, n2 = X.shape[0], Y.shape[0]\n",
    "    columns = [np.array([x] * n2) for x in X]    \n",
    "    dot_products =[kernel(col, Y) for col in columns]\n",
    "    return np.vstack(dot_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "n_samples = 2000\n",
    "train_examples = train_data[0: n_samples]\n",
    "train_kernel = compute_kernel(train_examples, train_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_true = y_train[: n_samples]\n",
    "C = [0.001,0.02,0.04,0.05,0.06,0.07, 0.08, 0.1, 0.2, 0.5,0.6, 0.7,0.8, 0.9, 1.0, 2.0, 5.0, 7.0, 10.0,40.0,100.0]\n",
    "# print(max_C)\n",
    "max_acc = 0\n",
    "for slack in C: \n",
    "    clf = svm.SVC(C = slack, kernel='precomputed')\n",
    "    clf.fit(train_kernel, y_train_true)\n",
    "    y_train_pred = clf.predict(train_kernel)\n",
    "    acc = accuracy_score(y_train_true, y_train_pred)\n",
    "    if acc > max_acc:\n",
    "        max_acc = acc\n",
    "        max_C = slack\n",
    "# print(confusion_matrix(y_train_true, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(max_acc, max_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "n = 1000\n",
    "test_kernel = compute_kernel(test_data[:n], train_examples)\n",
    "y_pred = clf.predict(test_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true = y_test[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(accuracy_score(y_true, y_pred))\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
