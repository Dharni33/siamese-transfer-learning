{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda, Input, Subtract, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.backend.tensorflow_backend import set_session\n",
    "from utils import limited_gpu_memory_session\n",
    "set_session(limited_gpu_memory_session(0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '/home/Drive2/rishabh/'\n",
    "INIT_WEIGHTS = os.path.join(DATA_DIR, 'init_weights_omniglot.hdf5')\n",
    "CHECKPOINTED_WEIGHTS = os.path.join(DATA_DIR, 'checkpointed_weights_omniglot.hdf5')\n",
    "INIT_WEIGHTS = os.path.join(DATA_DIR, 'init_weights_omniglot.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19280 images belonging to 30 classes.\n",
      "Found 13180 images belonging to 20 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "image_width = 105\n",
    "image_height = 105\n",
    "image_size = (image_width, image_height)\n",
    "GEN_BATCH_SIZE = 512\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255,\n",
    "                rotation_range=10, width_shift_range=0.2,\n",
    "                height_shift_range = 0.2, shear_range=0.2,\n",
    "                zoom_range=0.2)\n",
    "\n",
    "train_dir = os.path.join(DATA_DIR, 'omniglot/python/images_background')\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,  target_size=image_size,\n",
    "        batch_size=GEN_BATCH_SIZE,\n",
    "        class_mode='sparse', color_mode=\"grayscale\",\n",
    "        shuffle=True)\n",
    "\n",
    "test_dir = os.path.join(DATA_DIR, 'omniglot/python/images_evaluation')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,  target_size=image_size, # this is the target directory\n",
    "        batch_size=GEN_BATCH_SIZE*4, color_mode=\"grayscale\",\n",
    "        class_mode='sparse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_33 (Conv2D)           (None, 96, 96, 64)        6464      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 42, 42, 128)       401536    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 21, 21, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 18, 18, 128)       262272    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 6, 6, 256)         524544    \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 4096)              37752832  \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 2048)              8390656   \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1024)              2098176   \n",
      "=================================================================\n",
      "Total params: 49,436,480\n",
      "Trainable params: 49,436,480\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.regularizers import l2\n",
    "\n",
    "W_init = 'glorot_uniform'\n",
    "input_shape = (105, 105, 1)\n",
    "reg, dropout = 0, 0.5\n",
    "#build convnet to use in each siamese 'leg'\n",
    "convnet = Sequential()\n",
    "convnet.add(Conv2D(64, (10,10), activation='relu',input_shape=input_shape,\n",
    "                   kernel_initializer=W_init, kernel_regularizer=l2(reg)))\n",
    "convnet.add(MaxPooling2D())\n",
    "convnet.add(Conv2D(128, (7,7), activation='relu', kernel_regularizer=l2(reg),\n",
    "                   kernel_initializer=W_init))\n",
    "convnet.add(MaxPooling2D())\n",
    "convnet.add(Conv2D(128,(4,4),activation='relu',kernel_initializer=W_init, kernel_regularizer=l2(reg)))\n",
    "convnet.add(MaxPooling2D())\n",
    "convnet.add(Conv2D(256,(4,4),activation='relu',kernel_initializer=W_init, kernel_regularizer=l2(reg)))\n",
    "convnet.add(Flatten())\n",
    "convnet.add(Dense(4096,activation=\"selu\",kernel_regularizer=l2(reg),kernel_initializer=W_init))\n",
    "convnet.add(Dropout(dropout))\n",
    "convnet.add(Dense(2048,activation=\"selu\",kernel_regularizer=l2(reg),kernel_initializer=W_init))\n",
    "convnet.add(Dropout(dropout))\n",
    "convnet.add(Dense(1024,activation=\"selu\",kernel_regularizer=l2(reg),kernel_initializer=W_init))\n",
    "# convnet.add(Lambda(lambda x : tf.nn.l2_normalize(x, dim=0, epsilon=1e-20)))\n",
    "print(convnet.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the loss functions for the siamese and triplet network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def l2_norm(x):\n",
    "    return K.sqrt(K.sum(K.square(x)))\n",
    "\n",
    "MARGIN = 0.2\n",
    "def triplet_loss(y_true, y_pred): # \n",
    "    return K.mean(K.maximum(0.0, y_pred + MARGIN) - y_true * 0, axis = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the siamese network built using the conv net defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_5 (InputLayer)             (None, 105, 105, 1)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_6 (InputLayer)             (None, 105, 105, 1)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "sequential_9 (Sequential)        (None, 1024)          49436480    input_5[0][0]                    \n",
      "                                                                   input_6[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "subtract_1 (Subtract)            (None, 1024)          0           sequential_9[1][0]               \n",
      "                                                                   sequential_9[2][0]               \n",
      "____________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)                (None, 1)             0           subtract_1[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 49,436,480\n",
      "Trainable params: 49,436,480\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "# encode each of the two inputs into a vector with the convnet\n",
    "left_input, right_input = Input(input_shape), Input(input_shape)\n",
    "encoded_l, encoded_r  = convnet(left_input), convnet(right_input)\n",
    "# merge two encoded inputs with a distance metric\n",
    "diff = Subtract()([encoded_l,encoded_r])\n",
    "prediction = Lambda(l2_norm, output_shape=(1,))(diff)\n",
    "# prediction = layers.Dot(axes = -1, normalize=False)([encoded_l, encoded_r])\n",
    "# prediction = Activation('sigmoid')(prediction)\n",
    "siamese_net = Model(inputs=[left_input,right_input],outputs=prediction)\n",
    "siamese_net.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the triplet network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_7 (InputLayer)             (None, 105, 105, 1)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_9 (InputLayer)             (None, 105, 105, 1)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_8 (InputLayer)             (None, 105, 105, 1)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "model_2 (Model)                  (None, 1)             49436480    input_7[0][0]                    \n",
      "                                                                   input_8[0][0]                    \n",
      "                                                                   input_7[0][0]                    \n",
      "                                                                   input_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "subtract_2 (Subtract)            (None, 1)             0           model_2[2][0]                    \n",
      "                                                                   model_2[1][0]                    \n",
      "====================================================================================================\n",
      "Total params: 49,436,480\n",
      "Trainable params: 49,436,480\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_triples = [Input(input_shape) for _ in range(3)]\n",
    "pos_output = siamese_net([input_triples[0], input_triples[1]])\n",
    "neg_output = siamese_net([input_triples[0], input_triples[2]])\n",
    "diff = Subtract()([neg_output, pos_output])\n",
    "triplet_net = Model(inputs = input_triples, outputs = diff)\n",
    "triplet_net.summary()\n",
    "triplet_net.save_weights(INIT_WEIGHTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the data generator to load batches of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import utils; reload(utils)\n",
    "from utils import TripletGenerator\n",
    "\n",
    "NUM_TRAIN_TRIPLETS = 4096\n",
    "NUM_VAL_TRIPLETS = 10000\n",
    "BATCH_SIZE = 128\n",
    "datagen = TripletGenerator(train_generator, test_generator, NUM_VAL_TRIPLETS, \n",
    "                           batch_sz=BATCH_SIZE, num_train_triplets=NUM_TRAIN_TRIPLETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
    "              patience=3, verbose = 1, min_lr=1e-8)\n",
    "early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=1e-4,\n",
    "                              patience=25,\n",
    "                              verbose=0, mode='auto')\n",
    "checkpointer = ModelCheckpoint(filepath=CHECKPOINTED_WEIGHTS, verbose=1, save_best_only=True, monitor='val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "adam = Adam(2e-4)\n",
    "triplet_net.compile(loss=triplet_loss, optimizer=adam)\n",
    "triplet_net.load_weights(INIT_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 19280\n",
    "STEPS_PER_EPOCH = (TRAIN_SIZE//GEN_BATCH_SIZE) * (NUM_TRAIN_TRIPLETS // (BATCH_SIZE))\n",
    "VALIDATION_STEPS = NUM_VAL_TRIPLETS//BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1183/1184 [============================>.] - ETA: 0s - loss: 0.2711Epoch 00000: val_loss improved from inf to 0.19997, saving model to /home/Drive2/rishabh/checkpointed_weights_omniglot.hdf5\n",
      "1184/1184 [==============================] - 254s - loss: 0.2710 - val_loss: 0.2000\n",
      "Epoch 2/500\n",
      "1183/1184 [============================>.] - ETA: 0s - loss: 0.2478Epoch 00001: val_loss did not improve\n",
      "1184/1184 [==============================] - 250s - loss: 0.2482 - val_loss: 0.2000\n",
      "Epoch 3/500\n",
      "1183/1184 [============================>.] - ETA: 0s - loss: 0.2977Epoch 00002: val_loss did not improve\n",
      "1184/1184 [==============================] - 250s - loss: 0.2975 - val_loss: 0.2000\n",
      "Epoch 4/500\n",
      "1183/1184 [============================>.] - ETA: 0s - loss: 0.3222Epoch 00003: val_loss did not improve\n",
      "1184/1184 [==============================] - 250s - loss: 0.3224 - val_loss: 0.2130\n",
      "Epoch 5/500\n",
      " 496/1184 [===========>..................] - ETA: 143s - loss: 0.4027"
     ]
    }
   ],
   "source": [
    "# triplet_net.load_weights(CHECKPOINTED_WEIGHTS)\n",
    "history = triplet_net.fit_generator(\n",
    "        datagen.next_train(),\n",
    "        steps_per_epoch=STEPS_PER_EPOCH,\n",
    "        epochs=500,\n",
    "        validation_data=datagen.next_val(),\n",
    "        validation_steps=VALIDATION_STEPS,\n",
    "        callbacks = [reduce_lr, checkpointer, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "triplet_net.load_weights(CHECKPOINTED_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "siamese_model_path = os.path.join(DATA_DIR, 'siamese_omniglot')\n",
    "siamese_net.save(siamese_model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
