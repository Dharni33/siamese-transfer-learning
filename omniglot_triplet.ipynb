{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda, Input, Subtract, Activation, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.backend.tensorflow_backend import set_session\n",
    "from utils import limited_gpu_memory_session\n",
    "set_session(limited_gpu_memory_session(0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '/home/Drive2/rishabh/'\n",
    "TRAIN_FEATURES = os.path.join(DATA_DIR, 'features_train_omniglot.npy')\n",
    "TEST_FEATURES = os.path.join(DATA_DIR, 'features_test_omniglot.npy')\n",
    "INIT_WEIGHTS = os.path.join(DATA_DIR, 'init_weights_omniglot_triplet.hdf5')\n",
    "CHECKPOINTED_WEIGHTS = os.path.join(DATA_DIR, 'checkpointed_weights_omniglot_triplet.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19280 images belonging to 964 classes.\n",
      "Found 13180 images belonging to 659 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "image_width = 105\n",
    "image_height = 105\n",
    "image_size = (image_width, image_height)\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "train_dir = os.path.join(DATA_DIR, 'omniglot_keras/images_background') # python/\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "        train_dir,  target_size=image_size,\n",
    "        batch_size = 19280,\n",
    "        class_mode='sparse', color_mode=\"grayscale\",\n",
    "        shuffle=True)\n",
    "\n",
    "test_dir = os.path.join(DATA_DIR, 'omniglot_keras/images_evaluation')\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "        test_dir,  target_size=image_size, # this is the target directory\n",
    "        batch_size = 13180, color_mode=\"grayscale\",\n",
    "        class_mode='sparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import utils; reload(utils)\n",
    "from utils import get_alphabet_to_index\n",
    "test_alphabet_to_index = get_alphabet_to_index(test_generator)\n",
    "train_alphabet_to_index = get_alphabet_to_index(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = train_generator.next()\n",
    "X_val, y_val = test_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_data(X):\n",
    "    counter = 0\n",
    "    for img in X:\n",
    "        plt.subplot(4, 5, counter+1)\n",
    "        counter += 1\n",
    "        plt.axis('off')\n",
    "        plt.imshow(img[:,:,0], cmap = 'gray', interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efdf4643b90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_data(X_val[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 105, 105, 1)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_2 (InputLayer)             (None, 105, 105, 1)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)        (None, 4096)          38947648    input_1[0][0]                    \n",
      "                                                                   input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "diff (Subtract)                  (None, 4096)          0           sequential_1[1][0]               \n",
      "                                                                   sequential_1[2][0]               \n",
      "____________________________________________________________________________________________________\n",
      "abs (Lambda)                     (None, 4096)          0           diff[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "output (Dense)                   (None, 1)             4097        abs[0][0]                        \n",
      "====================================================================================================\n",
      "Total params: 38,951,745\n",
      "Trainable params: 0\n",
      "Non-trainable params: 38,951,745\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.regularizers import l2\n",
    "from keras.models import load_model\n",
    "\n",
    "MODEL_FILE = os.path.join(DATA_DIR, 'siamese_omniglot.h5')\n",
    "siamese_net = load_model(MODEL_FILE)\n",
    "for layer in siamese_net.layers:\n",
    "    layer.trainable = False\n",
    "siamese_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "siamese_net.load_weights(os.path.join(DATA_DIR, 'checkpointed_weights_omniglot.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 96, 96, 64)        6464      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 42, 42, 128)       401536    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 21, 21, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 18, 18, 128)       262272    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 6, 6, 256)         524544    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              37752832  \n",
      "=================================================================\n",
      "Total params: 38,947,648\n",
      "Trainable params: 0\n",
      "Non-trainable params: 38,947,648\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "convnet = siamese_net.layers[2] #load_model(convnet_file)\n",
    "convnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Train Features..\n",
      "Saving Test Features..\n"
     ]
    }
   ],
   "source": [
    "from utils import get_available_gpus\n",
    "\n",
    "def create_train_test_features(model, X_train, X_val):\n",
    "    dev = get_available_gpus()\n",
    "    \n",
    "    # Train data\n",
    "    print(\"Saving Train Features..\")\n",
    "    with tf.device(dev[0]):\n",
    "        bottleneck_features_train = model.predict(X_train)\n",
    "    # save the output as a Numpy array\n",
    "    np.save(open(TRAIN_FEATURES, 'w'), bottleneck_features_train)\n",
    "    \n",
    "    # Test data\n",
    "    print(\"Saving Test Features..\")\n",
    "    with tf.device(dev[-1]):\n",
    "        bottleneck_features_test = model.predict(X_val)\n",
    "    # save the output as a Numpy array\n",
    "    np.save(open(TEST_FEATURES, 'w'), bottleneck_features_test)\n",
    "\n",
    "if os.path.exists(TEST_FEATURES):\n",
    "    create_train_test_features(convnet, X_train, X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1_input (InputLayer)  (None, 105, 105, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 96, 96, 64)        6464      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 42, 42, 128)       401536    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 21, 21, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 18, 18, 128)       262272    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 6, 6, 256)         524544    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "=================================================================\n",
      "Total params: 1,194,816\n",
      "Trainable params: 1,194,816\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# train_data = conv\n",
    "my_model = Model(inputs = convnet.inputs, outputs = convnet.get_layer('flatten_1').output)\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 4096)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_2 (InputLayer)             (None, 4096)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "subtract_1 (Subtract)            (None, 4096)          0           input_1[0][0]                    \n",
      "                                                                   input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)                (None, 4096)          0           subtract_1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "output (Dense)                   (None, 1)             4097        lambda_1[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 4,097\n",
      "Trainable params: 0\n",
      "Non-trainable params: 4,097\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "baseline_siamese_path = os.path.join(DATA_DIR, 'baseline_siamese_omniglot.h5')\n",
    "if os.path.exists(baseline_siamese_path):\n",
    "    INPUT_SHAPE = 4096\n",
    "    inputs = [Input(shape=(INPUT_SHAPE,)) for _ in range(2)]\n",
    "    diff = Subtract()(inputs)\n",
    "    both = Lambda( lambda x: K.abs(x), lambda x : x)(diff)\n",
    "    prediction = siamese_net.get_layer('output')(both)\n",
    "    baseline_siamese = Model(inputs = inputs, outputs=prediction)\n",
    "    baseline_siamese.summary()\n",
    "    baseline_siamese.save(baseline_siamese_path)\n",
    "else:\n",
    "    baseline_siamese = load_model(baseline_siamese_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w1 = baseline_siamese.get_weights() \n",
    "w2 = siamese_net.layers[-1].get_weights()\n",
    "for a, b in zip(w1, w1):\n",
    "    assert (a == b).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = np.load(TRAIN_FEATURES)\n",
    "test_data = np.load(TEST_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.41174769],\n",
       "       [ 0.62274861]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "siamese_net.predict([X_val[:2], X_val[1:3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.41174781],\n",
       "       [ 0.62274885]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_siamese.predict([test_data[:2], test_data[1:3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = my_model.predict(X_train)\n",
    "test_data = my_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.regularizers import l2, l1\n",
    "from keras.initializers import RandomNormal\n",
    "\n",
    "INPUT_SHAPE = 4096\n",
    "W_init = RandomNormal(mean=0, stddev=1e-2) #'glorot_uniform'\n",
    "b_init = RandomNormal(mean= 0.5, stddev=1e-2)\n",
    "def dense_relu_bn_dropout(x, size, dropout, alpha = 0.1, reg = 0):\n",
    "    x = Dense(size, kernel_regularizer = l2(reg), kernel_initializer=W_init, bias_initializer=b_init)(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "    x = Activation('selu')(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    return x\n",
    "\n",
    "def create_network(reg, dropout, alpha = 0.1):\n",
    "    inputs = Input(shape=(INPUT_SHAPE,))\n",
    "    x = dense_relu_bn_dropout(inputs, 4096, dropout, reg)\n",
    "    x = dense_relu_bn_dropout(x, 4096, dropout, reg)\n",
    "    x = dense_relu_bn_dropout(x, 2048, dropout, reg)\n",
    "    base_network = Model(inputs=inputs, outputs = x)\n",
    "    print(base_network.summary())\n",
    "    return base_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2048)              8390656   \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2048)              0         \n",
      "=================================================================\n",
      "Total params: 41,953,280\n",
      "Trainable params: 41,953,280\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "base_network = create_network(1e-3, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def l2_norm(x):\n",
    "    return K.sqrt(K.sum(K.square(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_19 (InputLayer)            (None, 4096)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_20 (InputLayer)            (None, 4096)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "model_6 (Model)                  (None, 2048)          41953280    input_19[0][0]                   \n",
      "                                                                   input_20[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "subtract_6 (Subtract)            (None, 2048)          0           model_6[3][0]                    \n",
      "                                                                   model_6[4][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)                (None, 1)             0           subtract_6[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 41,953,280\n",
      "Trainable params: 41,953,280\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_pair = [Input((INPUT_SHAPE,)) for _ in range(2)]\n",
    "outputs_base = [base_network(inp) for inp in input_pair]\n",
    "diff = Subtract()(outputs_base)\n",
    "euclidean_dist = Lambda(l2_norm, output_shape = lambda x : (x[0], 1))(diff)\n",
    "model = Model(inputs = input_pair, outputs = euclidean_dist)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = baseline_siamese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 7, 8, 3, 4, 5, 6, 0, 1, 2, 19]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_alphabet_to_index['Angelic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the  triplet loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MARGIN = 0.1\n",
    "def triplet_loss(y_true, y_pred): # \n",
    "    return K.mean(K.maximum(0.0, y_pred + MARGIN) - y_true * 0, axis = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the  triplet network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_22 (InputLayer)            (None, 4096)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_23 (InputLayer)            (None, 4096)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_21 (InputLayer)            (None, 4096)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "model_10 (Model)                 (None, 1)             41953280    input_21[0][0]                   \n",
      "                                                                   input_22[0][0]                   \n",
      "                                                                   input_22[0][0]                   \n",
      "                                                                   input_23[0][0]                   \n",
      "                                                                   input_21[0][0]                   \n",
      "                                                                   input_23[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "average_4 (Average)              (None, 1)             0           model_10[2][0]                   \n",
      "                                                                   model_10[3][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "subtract_7 (Subtract)            (None, 1)             0           average_4[0][0]                  \n",
      "                                                                   model_10[1][0]                   \n",
      "====================================================================================================\n",
      "Total params: 41,953,280\n",
      "Trainable params: 41,953,280\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Define the triplet network\n",
    "from keras.layers import Average\n",
    "input_triples = [Input((INPUT_SHAPE,)) for _ in range(3)]\n",
    "pos_output = model(input_triples[:-1])\n",
    "neg_output0 = model(input_triples[1:]) \n",
    "neg_output1 = model([input_triples[0], input_triples[2]])\n",
    "neg_output = Average()([neg_output0, neg_output1])\n",
    "diff = Subtract()([neg_output, pos_output])\n",
    "triplet_net = Model(inputs = input_triples, outputs = diff)\n",
    "triplet_net.summary()\n",
    "triplet_net.save_weights(INIT_WEIGHTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the data generator to load batches of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import utils; reload(utils)\n",
    "from utils import TripletGenerator\n",
    "\n",
    "NUM_TRAIN_TRIPLETS = 300000\n",
    "NUM_VAL_TRIPLETS = 10000\n",
    "BATCH_SIZE = 128\n",
    "datagen = TripletGenerator(train_data, y_train, test_data, y_val, num_val_triplets=NUM_VAL_TRIPLETS, \n",
    "                           batch_sz=BATCH_SIZE, num_train_triplets=NUM_TRAIN_TRIPLETS, \n",
    "                           train_alphabet_to_index = train_alphabet_to_index,\n",
    "                           test_alphabet_to_index = test_alphabet_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
    "              patience=3, verbose = 1, min_lr=1e-8)\n",
    "early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=1e-4,\n",
    "                              patience=25,\n",
    "                              verbose=0, mode='auto')\n",
    "checkpointer = ModelCheckpoint(filepath=CHECKPOINTED_WEIGHTS, verbose=1, save_best_only=True, monitor='val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STEPS_PER_EPOCH = NUM_TRAIN_TRIPLETS//BATCH_SIZE\n",
    "VALIDATION_STEPS = NUM_VAL_TRIPLETS//BATCH_SIZE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "adam = Adam(1e-7)\n",
    "triplet_net.compile(loss=triplet_loss, optimizer=adam, metrics=['accuracy'])\n",
    "triplet_net.load_weights(INIT_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1111/2343 [=============>................] - ETA: 39s - loss: 0.6654 - acc: 0.2250"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-a89e287cd3eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVALIDATION_STEPS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         callbacks = [reduce_lr, checkpointer, early_stopping])\n\u001b[0m",
      "\u001b[0;32m/home/rishabh/myEnv/local/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rishabh/myEnv/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2040\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2041\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2042\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2044\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rishabh/myEnv/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1760\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1762\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rishabh/myEnv/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rishabh/myEnv/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rishabh/myEnv/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rishabh/myEnv/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rishabh/myEnv/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rishabh/myEnv/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# triplet_net.load_weights(CHECKPOINTED_WEIGHTS)\n",
    "history = triplet_net.fit_generator(\n",
    "        datagen.next_train(),\n",
    "        steps_per_epoch=STEPS_PER_EPOCH,\n",
    "        epochs=500,\n",
    "        validation_data=datagen.next_val(),\n",
    "        validation_steps=VALIDATION_STEPS,\n",
    "        callbacks = [reduce_lr, checkpointer, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "triplet_net.load_weights(CHECKPOINTED_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12911167513774696, 0.0017472257789159199]\n"
     ]
    }
   ],
   "source": [
    "# triplet_net.load_weights(CHECKPOINTED_WEIGHTS)\n",
    "history = triplet_net.evaluate_generator(\n",
    "        datagen.next_train(),\n",
    "        steps=STEPS_PER_EPOCH)\n",
    "print(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
