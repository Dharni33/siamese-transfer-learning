{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda, Input, Subtract, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib; matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# % matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'/gpu:0']\n"
     ]
    }
   ],
   "source": [
    "from keras.backend.tensorflow_backend import set_session\n",
    "from utils import limited_gpu_memory_session, get_available_gpus\n",
    "set_session(limited_gpu_memory_session(0.85))\n",
    "print(get_available_gpus())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '/home/Drive2/rishabh/'\n",
    "INIT_WEIGHTS = os.path.join(DATA_DIR, 'init_weights_omniglot.hdf5')\n",
    "CHECKPOINTED_WEIGHTS = os.path.join(DATA_DIR, 'checkpointed_weights_omniglot.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Load the test and train datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19280 images belonging to 964 classes.\n",
      "Found 13180 images belonging to 659 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "image_width = 105\n",
    "image_height = 105\n",
    "image_size = (image_width, image_height)\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "train_dir = os.path.join(DATA_DIR, 'omniglot_keras/images_background') # python/\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "        train_dir,  target_size=image_size,\n",
    "        batch_size = 19280,\n",
    "        class_mode='sparse', color_mode=\"grayscale\",\n",
    "        shuffle=True)\n",
    "\n",
    "test_dir = os.path.join(DATA_DIR, 'omniglot_keras/images_evaluation')\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "        test_dir,  target_size=image_size, # this is the target directory\n",
    "        batch_size = 13180, color_mode=\"grayscale\",\n",
    "        class_mode='sparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = train_generator.next()\n",
    "X_val, y_val = test_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import get_alphabet_to_index\n",
    "val_alphabet_to_index = get_alphabet_to_index(test_generator)\n",
    "train_alphabet_to_index = get_alphabet_to_index(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngQ5QhEAHKEKgAxQh0AGKEOgARfwf4lM10TQciZcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8864568750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "to_plot = X_train[np.where(y_train == 0)[0]]\n",
    "for i in range(20):\n",
    "    plt.subplot(4, 5, i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(to_plot[i][:,:,0], cmap = 'gray', interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 96, 96, 64)        6464      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 42, 42, 128)       401536    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 21, 21, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 18, 18, 128)       262272    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 6, 6, 256)         524544    \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "embedding (Dense)            (None, 4096)              37752832  \n",
      "=================================================================\n",
      "Total params: 38,947,648\n",
      "Trainable params: 38,947,648\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.regularizers import l2\n",
    "from keras.initializers import RandomNormal\n",
    "\n",
    "W_init = RandomNormal(mean=0, stddev=1e-2) #'glorot_uniform'\n",
    "b_init = RandomNormal(mean= 0.5, stddev=1e-2)\n",
    "W_dense_init = RandomNormal(mean=0, stddev = 2e-1)\n",
    "\n",
    "input_shape = (105, 105, 1)\n",
    "reg = 1e-2\n",
    "#build convnet to use in each siamese 'leg'\n",
    "convnet = Sequential(name=\"convnet\")\n",
    "convnet.add(Conv2D(64, (10,10), activation='relu',input_shape=input_shape,\n",
    "                   kernel_initializer=W_init, bias_initializer=b_init, kernel_regularizer=l2(reg)))\n",
    "convnet.add(MaxPooling2D())\n",
    "convnet.add(Conv2D(128, (7,7), activation='relu', kernel_regularizer=l2(reg),\n",
    "                   kernel_initializer=W_init))\n",
    "convnet.add(MaxPooling2D())\n",
    "convnet.add(Conv2D(128,(4,4),activation='relu',kernel_initializer=W_init, bias_initializer=b_init, \n",
    "                   kernel_regularizer=l2(reg)))\n",
    "convnet.add(MaxPooling2D())\n",
    "convnet.add(Conv2D(256,(4,4),activation='relu',kernel_initializer=W_init, bias_initializer=b_init, \n",
    "                   kernel_regularizer=l2(reg)))\n",
    "convnet.add(Flatten())\n",
    "convnet.add(Dense(4096,activation=\"sigmoid\", kernel_regularizer=l2(reg),kernel_initializer=W_dense_init, \n",
    "                  bias_initializer=b_init, name = \"embedding\"))\n",
    "print(convnet.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the loss functions for the siamese and triplet network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def l2_norm(x):\n",
    "    return K.sqrt(K.sum(K.square(x)))\n",
    "\n",
    "MARGIN = 0.2\n",
    "def triplet_loss(y_true, y_pred): # \n",
    "    return K.mean(K.maximum(0.0, y_pred + MARGIN) - y_true * 0, axis = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the siamese network built using the conv net defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 105, 105, 1)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_2 (InputLayer)             (None, 105, 105, 1)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convnet (Sequential)             (None, 4096)          38947648    input_1[0][0]                    \n",
      "                                                                   input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "diff (Subtract)                  (None, 4096)          0           convnet[1][0]                    \n",
      "                                                                   convnet[2][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "abs (Lambda)                     (None, 4096)          0           diff[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "output (Dense)                   (None, 1)             4097        abs[0][0]                        \n",
      "====================================================================================================\n",
      "Total params: 38,951,745\n",
      "Trainable params: 38,951,745\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "left_input = Input(input_shape, name=\"input_1\")\n",
    "encoded_l = convnet(left_input)\n",
    "# with tf.device('/gpu:1'):\n",
    "right_input = Input(input_shape, name=\"input_2\")\n",
    "encoded_r  = convnet(right_input)\n",
    "\n",
    "# merge two encoded inputs with a distance metric\n",
    "diff = Subtract(name=\"diff\")([encoded_l,encoded_r])\n",
    "both = Lambda(lambda x : K.abs(x), output_shape = lambda x: x, name=\"abs\")(diff)\n",
    "prediction = Dense(1, activation='sigmoid', kernel_initializer=W_dense_init, \n",
    "                   bias_initializer = b_init, name=\"output\")(both)\n",
    "\n",
    "siamese_net = Model(inputs=[left_input, right_input],outputs=prediction, name=\"siamese_net\")\n",
    "siamese_net.summary()\n",
    "os.system(\"rm {}\".format(INIT_WEIGHTS))\n",
    "siamese_net.save_weights(INIT_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
    "learning_rate = 6e-5\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
    "              patience=2, verbose = 1, epsilon = 1e-2, min_lr=1e-8)\n",
    "early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=1e-4,\n",
    "                              patience=25,\n",
    "                              verbose=0, mode='auto')\n",
    "checkpointer = ModelCheckpoint(filepath=CHECKPOINTED_WEIGHTS, verbose=1, save_best_only=True, monitor='oneshot_acc')\n",
    "scheduler = LearningRateScheduler(lambda epoch : learning_rate * pow(0.95, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "\n",
    "class LossHistory(Callback):\n",
    "    \n",
    "    def __init__(self, X_val, y_val, alphabets={}):\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        self.alphabets = alphabets\n",
    "        self.matches = {}\n",
    "        for x in np.unique(y_val):\n",
    "            self.matches[x] = np.where(y_val == x)[0]\n",
    "        self.true_indices = np.arange(20)\n",
    "        self.one_shot_indices = list(self.one_shot_task(alph) for alph in self.alphabets \n",
    "                   for _ in range(2))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        one_shot_acc = self.one_shot_acc()\n",
    "        logs['oneshot_acc'] = one_shot_acc\n",
    "        print(\" oneshot_acc - {}\".format(one_shot_acc))\n",
    "        \n",
    "    def one_shot_acc(self):\n",
    "        acc = [self.compute_acc(index[0], index[1]) for index in self.one_shot_indices]\n",
    "        return np.mean(acc)\n",
    "    \n",
    "    def compute_acc(self, support, test):\n",
    "        X_support, X_test = self.X_val[support], self.X_val[test]\n",
    "        class_indices = self.compute_pred_class(X_test, X_support)\n",
    "        return (np.sum(class_indices == self.true_indices))/20.0\n",
    "\n",
    "    def one_shot_task(self, alph):\n",
    "        class_arr = self.alphabets[alph]\n",
    "        sample_classes = np.random.choice(class_arr, 20, replace = False)\n",
    "        train_arr, test_arr = [], []\n",
    "        drawers = np.random.choice(20, 2, replace = False)\n",
    "        support_arr = [self.matches[x][drawers[0]] for x in sample_classes] \n",
    "        test_arr = [self.matches[x][drawers[1]] for x in sample_classes]\n",
    "        return (support_arr, test_arr)\n",
    "        \n",
    "    def kernel(self, x, y):\n",
    "        return siamese_net.predict([x, y]).ravel()\n",
    "\n",
    "    def compute_pred_class(self, X, Y):\n",
    "        n = Y.shape[0]\n",
    "        columns = (np.array([x] * n) for x in X)    \n",
    "        pred_classes = np.array([np.argmax(self.kernel(col, Y)) for col in columns])\n",
    "        return pred_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_history = LossHistory(X_val, y_val, val_alphabet_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the data generator to load batches of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Training Pairs..\n",
      "Generating Validation Pairs..\n"
     ]
    }
   ],
   "source": [
    "import utils; reload(utils)\n",
    "from utils import DataGenerator\n",
    "\n",
    "NUM_TRAIN_PAIRS = 150000\n",
    "NUM_VAL_PAIRS = 10000\n",
    "BATCH_SIZE = 128\n",
    "datagen = DataGenerator(X_train, y_train, num_train_pairs = NUM_TRAIN_PAIRS,\n",
    "                        num_val_pairs = NUM_VAL_PAIRS, X_val = X_val,\n",
    "                        train_alphabet_to_index = train_alphabet_to_index,\n",
    "                        val_alphabet_to_index = val_alphabet_to_index,\n",
    "                        y_val = y_val, batch_sz = BATCH_SIZE, verbose = True)\n",
    "datagen.create_data_transformer(rotation_range=10, width_shift_range=0.01, \n",
    "                              height_shift_range=0.01, shear_range=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STEPS_PER_EPOCH = NUM_TRAIN_PAIRS // BATCH_SIZE\n",
    "VALIDATION_STEPS = NUM_VAL_PAIRS // BATCH_SIZE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "adam = Adam(learning_rate)\n",
    "siamese_net.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "siamese_net.load_weights(INIT_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "siamese_net.load_weights(CHECKPOINTED_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1170/1171 [============================>.] - ETA: 0s - loss: 0.5852 - acc: 0.8677 oneshot_acc - 0.615\n",
      "Epoch 00000: oneshot_acc improved from -inf to 0.61500, saving model to /home/Drive2/rishabh/checkpointed_weights_omniglot.hdf5\n",
      "1171/1171 [==============================] - 184s - loss: 0.5852 - acc: 0.8676 - val_loss: 0.5433 - val_acc: 0.8532\n",
      "Epoch 2/500\n",
      "1170/1171 [============================>.] - ETA: 0s - loss: 0.4883 - acc: 0.8755 oneshot_acc - 0.60875\n",
      "Epoch 00001: oneshot_acc did not improve\n",
      "1171/1171 [==============================] - 179s - loss: 0.4883 - acc: 0.8755 - val_loss: 0.5314 - val_acc: 0.8494\n",
      "Epoch 3/500\n",
      "1170/1171 [============================>.] - ETA: 0s - loss: 0.4799 - acc: 0.8779 oneshot_acc - 0.61375\n",
      "Epoch 00002: oneshot_acc did not improve\n",
      "1171/1171 [==============================] - 181s - loss: 0.4799 - acc: 0.8779 - val_loss: 0.5244 - val_acc: 0.8547\n",
      "Epoch 4/500\n",
      " 297/1171 [======>.......................] - ETA: 127s - loss: 0.4776 - acc: 0.8810"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-2f869876c2a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVALIDATION_STEPS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         callbacks = [scheduler, reduce_lr, early_stopping, loss_history, checkpointer])\n\u001b[0m",
      "\u001b[0;32m/home/rishabh/myEnv/local/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rishabh/myEnv/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2040\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2041\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2042\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2044\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rishabh/myEnv/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1760\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1762\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rishabh/myEnv/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rishabh/myEnv/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rishabh/myEnv/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rishabh/myEnv/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rishabh/myEnv/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rishabh/myEnv/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = siamese_net.fit_generator(\n",
    "        datagen.next_train(),\n",
    "        steps_per_epoch=STEPS_PER_EPOCH,\n",
    "        epochs=500,\n",
    "        validation_data = datagen.next_val(),\n",
    "        validation_steps = VALIDATION_STEPS,\n",
    "        callbacks = [scheduler, reduce_lr, early_stopping, loss_history, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\n",
    "f.set_figheight(8)\n",
    "f.set_figwidth(14)\n",
    "\n",
    "ax1.plot(history.history['loss'])\n",
    "ax1.plot(history.history['val_loss'])\n",
    "ax1.set_title('model loss')\n",
    "ax1.set_ylabel('loss')\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.legend(['train_loss' 'val'], loc='upper left')\n",
    "\n",
    "ax2.plot(history.history['acc'])\n",
    "ax2.plot(history.history['val_acc'])\n",
    "ax2.set_title('model acc')\n",
    "ax2.set_ylabel('acc')\n",
    "ax2.set_xlabel('epoch')\n",
    "ax2.legend(['train_acc' 'val'], loc='upper left')\n",
    "\n",
    "f.savefig('siamese_omniglot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "siamese_net.load_weights(CHECKPOINTED_WEIGHTS)\n",
    "for layer in siamese_net.layers:\n",
    "    layer.trainable = False\n",
    "siamese_net.summary()\n",
    "siamese_net.save(os.path.join(DATA_DIR, 'siamese_omniglot1.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "siamese_net = load_model(os.path.join(DATA_DIR, 'siamese_omniglot1.h5'))\n",
    "siamese_net.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history = siamese_net.evaluate_generator(datagen.next_val(),\n",
    "        steps=VALIDATION_STEPS)\n",
    "print(\"Loss {} Accuracy {}\".format(history[0], history[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
